# Module 2: Fine-Tuning LLMs and Domain Adaptation

<div align="center">
  <img src="images/module-2-cover.png" alt="Module 2 Cover - Fine-Tuning LLMs and Domain Adaptation" width="800">
</div>

Welcome to Module 2 of the Open Source LLM Zoomcamp! In this module, we'll explore fine-tuning Large Language Models (LLMs) and adapting them to specific domains using Llama Factory.

* Video Link (Coming Soon)
* Slides (Coming Soon)

## Table of Contents
- [Learning Objectives](#learning-objectives)
- [1. Introduction](#1-introduction)
  - [1.1 Introduction to Fine-Tuning](#11-introduction-to-fine-tuning)
  - [1.2 Getting Started with Llama Factory](#12-getting-started-with-llama-factory)
- [2. Environment Setup](#2-environment-setup)
  - [2.1 Dataset Preparation](#21-dataset-preparation)
  - [2.2 Training Environment Setup](#22-training-environment-setup)
- [3. Hands-on Fine-Tuning](#3-hands-on-fine-tuning)
  - [3.1 DeepSeek R1 Fine-Tuning Tutorial](#31-deepseek-r1-fine-tuning-tutorial)
  - [3.2 Enhancing the Chatbot](#32-enhancing-the-chatbot)
- [4. Advanced Topics: Text-to-Image Model Adaptation](#4-advanced-topics-text-to-image-model-adaptation-optional)
- [5. Homework: Fine-Tuning an Open-Source LLM](#5-homework-fine-tuning-an-open-source-llm)
- [Community Notes](#community-notes)

## Learning Objectives
- Understand the fundamentals of LLM fine-tuning
- Learn how to use Llama Factory for model adaptation
- Prepare and process datasets for fine-tuning
- Gain hands-on experience fine-tuning DeepSeek R1
- Improve the chatbot developed in Module 1
- (Bonus) Explore text-to-image model adaptations

We recommend watching the videos in the order presented in this document.

# 1. Introduction
## 1.1 Introduction to Fine-Tuning

* What is fine-tuning and when to use it
* Different approaches to model adaptation
* Understanding training dynamics
* Trade-offs and considerations
* Cost and computational requirements

## 1.2 Getting Started with Llama Factory

* Introduction to Llama Factory ecosystem
* Key features and capabilities
* Configuration options and parameters
* Best practices for fine-tuning

# 2. Environment Setup

## 2.1 Dataset Preparation

* Data collection and curation strategies
* Dataset formats and requirements
* Data cleaning and preprocessing
* Quality assurance and validation
* Common pitfalls and how to avoid them

## 2.2 Training Environment Setup

* Setting up Llama Factory
* Configuring training parameters
* Managing model checkpoints
* Monitoring training progress
* Resource requirements and optimization

# 3. Hands-on Fine-Tuning

## 3.1 DeepSeek R1 Fine-Tuning Tutorial

* Model overview and capabilities
* Preparing the training data
* Configuring the training run
* Monitoring and evaluation
* Exporting the fine-tuned model

## 3.2 Enhancing the Chatbot

* Integrating the fine-tuned model
* Improving response quality
* Performance optimization
* Best practices for deployment
* A/B testing and evaluation

# 4. Advanced Topics: Text-to-Image Model Adaptation (Optional)

* Introduction to text-to-image models
* Fine-tuning approaches
* Use cases and applications
* Hands-on examples
* Performance considerations

# 5. Homework: Fine-Tuning an Open-Source LLM

The goal of this homework is to get hands-on experience with fine-tuning an open-source LLM for a specific use case.

### Part 1: Model Fine-Tuning

Choose a base model (e.g., DeepSeek R1) and:
1. Prepare a suitable dataset for your use case
2. Configure the fine-tuning process
3. Run the training
4. Document the following metrics:
   * Training time
   * Resource usage
   * Loss curves
   * Evaluation metrics
5. Compare the fine-tuned model with the base model

### Part 2: Model Evaluation

Using your fine-tuned model:
1. Set up an evaluation pipeline that measures:
   * Task-specific metrics
   * Generation quality
   * Response consistency
2. Compare performance with the base model
3. Document improvements and limitations

# Community Notes

Did you take notes? You can share them here:

* Add your notes here!

